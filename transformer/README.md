# Attention Is All You Need
Vaswani et al. proposed a new simple network architecture, the Transformer,
based solely on attention mechanisms, dispensing with recurrence and convolutions
entirely.
<p align="center">
  <img alt="Vision Transformer" src="https://user-images.githubusercontent.com/46085301/193833458-b848d448-086d-4417-a42d-225926305624.png" height="500"/>
</P>


## ðŸ“šReferences:
- Vaswani et al. (2017). Attention Is All You Need. arXiv. https://doi.org/10.48550/arXiv.1706.03762
- Dosovitskiy et al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. arXiv. https://doi.org/10.48550/arXiv.2010.11929
- Papers with Code - Vision Transformer Explained. (n.d.). https://paperswithcode.com/method/vision-transformer
